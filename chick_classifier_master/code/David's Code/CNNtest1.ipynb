{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import required libaries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "#KERAS\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# SKLEARN\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory location for image data - USE OWN DIRECTORY HERE\n",
    "DATADIR = '/Users/David/Desktop/CNN-image-classifier/training_data'\n",
    "#Sub directories for different categories\n",
    "CATEGORIES = [\"10_1\",\"10_2\",\"10_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add all images to training data\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # 10_1, 10_2, 10_3\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to different stages\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0, 1 or 2)\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                training_data.append([img_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "            #except OSError as e:\n",
    "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
    "            #except Exception as e:\n",
    "            #    print(\"general exception\", e, os.path.join(path,img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [00:01<00:00, 915.15it/s]\n",
      "100%|██████████| 1320/1320 [00:01<00:00, 958.54it/s]\n",
      "100%|██████████| 1008/1008 [00:01<00:00, 965.62it/s]\n"
     ]
    }
   ],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3624\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle training_data so that 10_1s, 10_2s and 10_3s are not together\n",
    "import random\n",
    "\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] #Images\n",
    "y = [] #Labels\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 200, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2899, 200, 200, 1)\n",
      "2899 train samples\n",
      "725 test samples\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size to train\n",
    "batch_size = 32\n",
    "# number of output classes\n",
    "nb_classes = 3\n",
    "# number of epochs to train\n",
    "nb_epoch = 20\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/David/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(200, 200,..., padding=\"valid\")`\n",
      "  \"\"\"\n",
      "/Users/David/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv,\n",
    "                        border_mode='valid',\n",
    "                        input_shape=(img_rows, img_cols,1)))\n",
    "convout1 = Activation('relu')\n",
    "model.add(convout1)\n",
    "model.add(Convolution2D(nb_filters, nb_conv, nb_conv))\n",
    "convout2 = Activation('relu')\n",
    "model.add(convout2)\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/David/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/David/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2899 samples, validate on 725 samples\n",
      "Epoch 1/20\n",
      "2899/2899 [==============================] - 595s 205ms/step - loss: 1.2546 - accuracy: 0.3819 - val_loss: 1.0513 - val_accuracy: 0.4621\n",
      "Epoch 2/20\n",
      "2899/2899 [==============================] - 557s 192ms/step - loss: 1.0365 - accuracy: 0.4577 - val_loss: 1.0440 - val_accuracy: 0.4538\n",
      "Epoch 3/20\n",
      "2899/2899 [==============================] - 553s 191ms/step - loss: 1.0195 - accuracy: 0.4953 - val_loss: 1.0193 - val_accuracy: 0.4993\n",
      "Epoch 4/20\n",
      "2899/2899 [==============================] - 553s 191ms/step - loss: 1.0019 - accuracy: 0.5060 - val_loss: 1.0354 - val_accuracy: 0.4897\n",
      "Epoch 5/20\n",
      "2899/2899 [==============================] - 527s 182ms/step - loss: 0.9697 - accuracy: 0.5281 - val_loss: 1.0243 - val_accuracy: 0.5048\n",
      "Epoch 6/20\n",
      "2899/2899 [==============================] - 527s 182ms/step - loss: 0.9430 - accuracy: 0.5433 - val_loss: 1.0003 - val_accuracy: 0.5048\n",
      "Epoch 7/20\n",
      "2899/2899 [==============================] - 546s 188ms/step - loss: 0.9175 - accuracy: 0.5833 - val_loss: 1.0054 - val_accuracy: 0.5324\n",
      "Epoch 8/20\n",
      "2899/2899 [==============================] - 569s 196ms/step - loss: 0.8788 - accuracy: 0.6002 - val_loss: 0.9997 - val_accuracy: 0.5186\n",
      "Epoch 9/20\n",
      "2899/2899 [==============================] - 539s 186ms/step - loss: 0.8182 - accuracy: 0.6371 - val_loss: 1.0251 - val_accuracy: 0.5476\n",
      "Epoch 10/20\n",
      "2899/2899 [==============================] - 532s 184ms/step - loss: 0.7850 - accuracy: 0.6551 - val_loss: 1.0422 - val_accuracy: 0.5145\n",
      "Epoch 11/20\n",
      "2899/2899 [==============================] - 551s 190ms/step - loss: 0.7069 - accuracy: 0.6851 - val_loss: 1.0671 - val_accuracy: 0.5655\n",
      "Epoch 12/20\n",
      "2899/2899 [==============================] - 539s 186ms/step - loss: 0.6438 - accuracy: 0.7316 - val_loss: 1.0193 - val_accuracy: 0.5876\n",
      "Epoch 13/20\n",
      "2899/2899 [==============================] - 556s 192ms/step - loss: 0.5882 - accuracy: 0.7558 - val_loss: 1.1251 - val_accuracy: 0.5586\n",
      "Epoch 14/20\n",
      "2899/2899 [==============================] - 573s 198ms/step - loss: 0.5091 - accuracy: 0.7961 - val_loss: 1.0429 - val_accuracy: 0.5903\n",
      "Epoch 15/20\n",
      "2899/2899 [==============================] - 580s 200ms/step - loss: 0.4482 - accuracy: 0.8175 - val_loss: 1.0678 - val_accuracy: 0.6041\n",
      "Epoch 16/20\n",
      "2899/2899 [==============================] - 646s 223ms/step - loss: 0.3866 - accuracy: 0.8493 - val_loss: 1.0503 - val_accuracy: 0.6386\n",
      "Epoch 17/20\n",
      "2899/2899 [==============================] - 560s 193ms/step - loss: 0.3156 - accuracy: 0.8765 - val_loss: 1.0531 - val_accuracy: 0.6593\n",
      "Epoch 18/20\n",
      "2899/2899 [==============================] - 614s 212ms/step - loss: 0.2828 - accuracy: 0.8907 - val_loss: 1.1683 - val_accuracy: 0.6372\n",
      "Epoch 19/20\n",
      "2899/2899 [==============================] - 587s 202ms/step - loss: 0.2601 - accuracy: 0.9003 - val_loss: 1.1857 - val_accuracy: 0.6110\n",
      "Epoch 20/20\n",
      "2899/2899 [==============================] - 593s 204ms/step - loss: 0.2339 - accuracy: 0.9172 - val_loss: 1.1759 - val_accuracy: 0.6634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a734d0390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                verbose=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.1759061956405639\n",
      "Test accuracy: 0.6634482741355896\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
